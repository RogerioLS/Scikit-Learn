{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo introdutório para combinar modelos\n",
    "\n",
    "Este primeiro caderno visa enfatizar o benefício dos métodos de conjunto sobre\n",
    "modelos simples (por exemplo, árvore de decisão, modelo linear, etc.). Combinando simples\n",
    "modelos resultam em modelos mais poderosos e robustos com menos complicações.\n",
    "\n",
    "Começaremos carregando o conjunto de dados de habitação da Califórnia. Lembramos que o\n",
    "objetivo neste conjunto de dados é prever o valor médio da casa em algum distrito\n",
    "na Califórnia, com base em dados demográficos e geográficos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\"> Se você quiser uma visão geral mais detalhada sobre este conjunto de dados, pode consultar o\n",
    "Apêndice - seção de descrição dos conjuntos de dados no final deste MOOC. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        452.6\n",
       "1        358.5\n",
       "2        352.1\n",
       "3        341.3\n",
       "4        342.2\n",
       "         ...  \n",
       "20635     78.1\n",
       "20636     77.1\n",
       "20637     92.3\n",
       "20638     84.7\n",
       "20639     89.4\n",
       "Name: MedHouseVal, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data, target = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificaremos o desempenho estatístico do regressor de árvore de decisão com\n",
    "parâmetros padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score obtained by cross-validation: 0.354 +/- 0.087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state=0)\n",
    "cv_results = cross_validate(tree, data, target, n_jobs=-1)\n",
    "scores = cv_results[\"test_score\"]\n",
    "\n",
    "print(f\"R2 score obtained by cross-validation: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos resultados justos. No entanto, como apresentamos anteriormente na \"tree in depth\", este modelo precisa ser ajustado para superar ou\n",
    "insuficiente. Na verdade, os parâmetros padrão não levarão necessariamente a um\n",
    "árvore de decisão ótima. Em vez de usar o valor padrão, devemos pesquisar\n",
    "por meio de validação cruzada, o valor ideal dos parâmetros importantes, como\n",
    "`max_depth`,` min_samples_split` ou `min_samples_leaf`.\n",
    "\n",
    "Lembramos que precisamos ajustar esses parâmetros, pois as árvores de decisão tendem a\n",
    "ajustar demais os dados de treinamento se cultivarmos árvores profundas, mas não há regras sobre\n",
    "como cada parâmetro deve ser definido. Assim, não fazer uma pesquisa pode nos levar\n",
    "ter um modelo insuficiente ou superaquecido.\n",
    "\n",
    "Agora, fazemos uma pesquisa em grade para ajustar os hiperparâmetros que mencionamos\n",
    "mais cedo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score obtained by cross-validation: 0.523 +/- 0.107\n",
      "Wall time: 8.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [5, 8, None],\n",
    "    \"min_samples_split\": [2, 10, 30, 50],\n",
    "    \"min_samples_leaf\": [0.01, 0.05, 0.1, 1]}\n",
    "cv = 3\n",
    "\n",
    "tree = GridSearchCV(DecisionTreeRegressor(random_state=0),\n",
    "                    param_grid=param_grid, cv=cv, n_jobs=-1)\n",
    "cv_results = cross_validate(tree, data, target, n_jobs=-1,\n",
    "                            return_estimator=True)\n",
    "scores = cv_results[\"test_score\"]\n",
    "\n",
    "print(f\"R2 score obtained by cross-validation: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que otimizar os hiperparâmetros terá um efeito positivo\n",
    "sobre o desempenho estatístico. No entanto, ele vem com um alto desempenho computacional\n",
    "custo.\n",
    "\n",
    "Podemos criar um dataframe armazenando as informações importantes coletadas durante\n",
    "o ajuste dos parâmetros e investigação dos resultados.\n",
    "\n",
    "Agora usaremos um método de ensemble chamado bagging. Mais detalhes sobre isso\n",
    "método será discutido na próxima seção. Em suma, este método usará\n",
    "um regressor de base (ou seja, regressores de árvore de decisão) e treinará vários dos\n",
    "em uma versão ligeiramente modificada do conjunto de treinamento. Então o\n",
    "as previsões de todos esses regressores de base serão combinadas pela média.\n",
    "\n",
    "Aqui, usaremos 50 árvores de decisão e verificaremos o tempo de ajuste, bem como o\n",
    "desempenho estatístico nos dados de teste deixados de fora. É importante notar\n",
    "que não vamos ajustar nenhum parâmetro da árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score obtained by cross-validation: 0.642 +/- 0.083\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "base_estimator = DecisionTreeRegressor(random_state=0)\n",
    "bagging_regressor = BaggingRegressor(\n",
    "    base_estimator=base_estimator, n_estimators=20, random_state=0)\n",
    "\n",
    "cv_results = cross_validate(bagging_regressor, data, target, n_jobs=-1)\n",
    "scores = cv_results[\"test_score\"]\n",
    "\n",
    "print(f\"R2 score obtained by cross-validation: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sem procurar hiperparâmetros ideais, a estatística geral\n",
    "o desempenho do regressor de bagging é melhor do que uma única árvore de decisão.\n",
    "Além disso, o custo computacional é reduzido em comparação com a busca\n",
    "para os hiperparâmetros ideais.\n",
    "\n",
    "Isso mostra a motivação por trás do uso de um aluno de conjunto: dá uma\n",
    "linha de base relativamente boa com desempenho estatístico decente, sem qualquer\n",
    "ajuste de parâmetro.\n",
    "\n",
    "Agora, vamos discutir em detalhes dois ensemble families: bagging and\n",
    "boosting:\n",
    "\n",
    "* ensemble using bootstrap (e.g. bagging and random-forest);\n",
    "* ensemble using boosting (e.g. adaptive boosting and gradient-boosting\n",
    "  decision tree)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
