{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Na seção anterior, não discutimos os parâmetros de floresta aleatória e aumento de gradiente. No entanto, há algumas coisas que você deve ter em mente ao configurá-los.\n",
    "\n",
    "Este bloco de notas fornece informações cruciais sobre como definir os hiperparâmetros dos modelos de árvore de decisão de aumento de gradiente e floresta aleatória."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p>Por motivos de clareza, nenhuma cross-validation será usada para estimar o erro de teste. Estamos apenas mostrando o efeito dos parâmetros no conjunto de validação do que deveria ser a cross-validation interna.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "O parâmetro principal para ajustar para floresta aleatória é o parâmetro `n_estimators`. Em geral, quanto mais árvores na floresta, melhor será o desempenho de generalização. No entanto, isso diminuirá o tempo de adaptação e previsão. O objetivo é equilibrar o tempo de computação e o desempenho de generalização ao definir o número de estimadores ao colocar esse aluno em produção.\n",
    "\n",
    "O parâmetro `max_depth` também pode ser ajustado. Às vezes, não há necessidade de árvores totalmente crescidas. No entanto, esteja ciente de que, com floresta aleatória, as árvores são geralmente profundas, pois estamos procurando ajustar os alunos nas amostras de bootstrap, pois isso será atenuado combinando-as. A montagem de árvores mal ajustadas (ou seja, árvores rasas) também pode levar a uma floresta mal ajustada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>34.491224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>34.852569</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>35.997110</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>48.691969</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>48.719785</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>48.782024</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>56.941830</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>57.000582</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>57.337783</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_depth  mean_test_score  rank_test_score\n",
       "8                 30            None        34.491224                1\n",
       "7                 20            None        34.852569                2\n",
       "6                 10            None        35.997110                3\n",
       "4                 20               5        48.691969                4\n",
       "5                 30               5        48.719785                5\n",
       "3                 10               5        48.782024                6\n",
       "2                 30               3        56.941830                7\n",
       "1                 20               3        57.000582                8\n",
       "0                 10               3        57.337783                9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 20, 30],\n",
    "    \"max_depth\": [3, 5, None],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(n_jobs=2), param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=2,\n",
    ")\n",
    "grid_search.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que em nossa pesquisa em grade, o maior `max_depth` junto com os maiores `n_estimators` levou ao melhor desempenho de generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosting decision trees\n",
    "\n",
    "Para o aumento de gradiente, os parâmetros são acoplados, portanto, não podemos mais definir os parâmetros um após o outro. Os parâmetros importantes são `n_estimators`, `max_depth` e `learning_rate`.\n",
    "\n",
    "Vamos primeiro discutir o parâmetro max_depth. Vimos na seção sobre aumento de gradiente que o algoritmo se ajusta ao erro da árvore anterior no conjunto. Assim, caber em árvores totalmente crescidas será prejudicial. Na verdade, a primeira árvore do conjunto se ajustaria perfeitamente (superadaptaria) aos dados e, portanto, nenhuma árvore subsequente seria necessária, uma vez que não haveria resíduos. Portanto, a árvore usada no aumento de gradiente deve ter uma profundidade baixa, normalmente entre 3 a 8 níveis. Ter alunos muito fracos em cada etapa ajudará a reduzir o sobreajuste.\n",
    "\n",
    "Com essa consideração em mente, quanto mais profundas as árvores, mais rápido os resíduos serão corrigidos e menos alunos serão necessários. Portanto, `n_estimators` deve ser aumentado se `max_depth` for menor.\n",
    "\n",
    "Finalmente, esquecemos o impacto do parâmetro `learning_rate` até agora. Ao ajustar os resíduos, gostaríamos que a árvore tentasse corrigir todos os erros possíveis ou apenas uma fração deles. A taxa de aprendizado permite que você controle esse comportamento. Um pequeno valor de taxa de aprendizagem corrige apenas os resíduos de muito poucas amostras. Se uma grande taxa de aprendizado for definida (por exemplo, 1), ajustaríamos os resíduos de todas as amostras. Portanto, com uma taxa de aprendizado muito baixa, precisaremos de mais estimadores para corrigir o erro geral. No entanto, uma taxa de aprendizagem muito grande tende a obter um conjunto superaquecido, semelhante a uma árvore com uma profundidade muito grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>35.664653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36.703013</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>37.458088</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.056313</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>39.354899</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.450557</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.730580</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40.602042</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41.602175</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45.588320</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45.756084</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45.863965</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>47.245184</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>47.305145</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>47.519112</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>51.961816</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>56.354543</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>62.270268</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_max_depth param_learning_rate  mean_test_score  \\\n",
       "5                  50               5                 0.1        35.664653   \n",
       "11                 50               3                   1        36.703013   \n",
       "10                 30               3                   1        37.458088   \n",
       "13                 30               5                   1        39.056313   \n",
       "4                  30               5                 0.1        39.354899   \n",
       "12                 10               5                   1        39.450557   \n",
       "14                 50               5                   1        39.730580   \n",
       "2                  50               3                 0.1        40.602042   \n",
       "9                  10               3                   1        41.602175   \n",
       "7                  30            None                 0.1        45.588320   \n",
       "1                  30               3                 0.1        45.756084   \n",
       "8                  50            None                 0.1        45.863965   \n",
       "17                 50            None                   1        47.245184   \n",
       "16                 30            None                   1        47.305145   \n",
       "15                 10            None                   1        47.519112   \n",
       "6                  10            None                 0.1        51.961816   \n",
       "3                  10               5                 0.1        56.354543   \n",
       "0                  10               3                 0.1        62.270268   \n",
       "\n",
       "    rank_test_score  \n",
       "5                 1  \n",
       "11                2  \n",
       "10                3  \n",
       "13                4  \n",
       "4                 5  \n",
       "12                6  \n",
       "14                7  \n",
       "2                 8  \n",
       "9                 9  \n",
       "7                10  \n",
       "1                11  \n",
       "8                12  \n",
       "17               13  \n",
       "16               14  \n",
       "15               15  \n",
       "6                16  \n",
       "3                17  \n",
       "0                18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 30, 50],\n",
    "    \"max_depth\": [3, 5, None],\n",
    "    \"learning_rate\": [0.1, 1],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    GradientBoostingRegressor(), param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=2\n",
    ")\n",
    "grid_search.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p>Aqui, ajustamos os n_estimators, mas esteja ciente de que usar a parada antecipada como no exercício anterior será melhor.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📝 Exercício M6.05\n",
    "\n",
    "O objetivo do exercício é familiarizar-se com o aumento de gradiente do histograma no scikit-learn. Além disso, usaremos este modelo em uma estrutura de validação cruzada para inspecionar parâmetros internos encontrados por meio de pesquisa em grade.\n",
    "\n",
    "Usaremos o conjunto de dados de habitação da Califórnia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, crie um regressor de aumento de gradiente de histograma. Você pode definir o número de árvores para ser grande e configurar o modelo para usar a parada antecipada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "hist_gbdt = HistGradientBoostingRegressor(\n",
    "    max_iter=1000, early_stopping=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos uma pesquisa em grade para encontrar algum parâmetro ideal para este modelo. Nesta pesquisa em grade, você deve pesquisar os seguintes parâmetros:\n",
    "\n",
    "* `max_depth: [3, 8]`;\n",
    "* `max_leaf_nodes: [15, 31]`;\n",
    "* `learning_rate: [0,1, 1]`.\n",
    "\n",
    "Sinta-se à vontade para explorar o espaço com valores adicionais. Crie a pesquisa em grade fornecendo a instância de aumento de gradiente anterior como o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": [3, 8],\n",
    "    \"max_leaf_nodes\": [15, 31],\n",
    "    \"learning_rate\": [0.1, 1],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(hist_gbdt, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, faremos nosso experimento por meio de validação cruzada. A este respeito, defina uma validação cruzada de 5 vezes. Além disso, certifique-se de embaralhar os dados. Posteriormente, use a função `sklearn.model_selection.cross_validate` para executar a validação cruzada. Você também deve definir `return_estimator = True`, para que possamos investigar o modelo interno treinado por meio de validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "results = cross_validate(\n",
    "    search, data, target, cv=cv, return_estimator=True, n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que obtivemos os resultados da validação cruzada, imprima a pontuação média e o desvio padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score with cross-validation:\n",
      "0.839 +/- 0.006\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "print(f\"R2 score with cross-validation:\\n\"\n",
    "      f\"{results['test_score'].mean():.3f} +/- \"\n",
    "      f\"{results['test_score'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, inspecione a entrada do `estimator` dos resultados e verifique os melhores valores dos parâmetros. Além disso, verifique a quantidade de árvores utilizadas pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_leaf_nodes': 15}\n",
      "# trees: 528\n",
      "{'learning_rate': 0.1, 'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "# trees: 447\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_leaf_nodes': 15}\n",
      "# trees: 576\n",
      "{'learning_rate': 0.1, 'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "# trees: 290\n",
      "{'learning_rate': 0.1, 'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "# trees: 414\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "for estimator in results[\"estimator\"]:\n",
    "    print(estimator.best_params_)\n",
    "    print(f\"# trees: {estimator.best_estimator_.n_iter_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecione os resultados do CV interno para cada estimador do CV externo. Agregue a pontuação média do teste para cada combinação de parâmetros e faça um gráfico de caixa dessas pontuações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "import pandas as pd\n",
    "\n",
    "index_columns = [f\"param_{name}\" for name in params.keys()]\n",
    "columns = index_columns + [\"mean_test_score\"]\n",
    "\n",
    "inner_cv_results = []\n",
    "for cv_idx, estimator in enumerate(results[\"estimator\"]):\n",
    "    search_cv_results = pd.DataFrame(estimator.cv_results_)\n",
    "    search_cv_results = search_cv_results[columns].set_index(index_columns)\n",
    "    search_cv_results = search_cv_results.rename(\n",
    "        columns={\"mean_test_score\": f\"CV {cv_idx}\"})\n",
    "    inner_cv_results.append(search_cv_results)\n",
    "inner_cv_results = pd.concat(inner_cv_results, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color = {\"whiskers\": \"black\", \"medians\": \"black\", \"caps\": \"black\"}\n",
    "inner_cv_results.plot.box(vert=False, color=color)\n",
    "plt.xlabel(\"R2 score\")\n",
    "plt.ylabel(\"Parameters\")\n",
    "_ = plt.title(\"Inner CV results with parameters\\n\"\n",
    "              \"(max_depth, max_leaf_nodes, learning_rate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que os primeiros 4 conjuntos de parâmetros classificados estão muito próximos. Podemos selecionar qualquer uma dessas 4 combinações. Ele coincide com os resultados que observamos ao inspecionar os melhores parâmetros do CV externo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
