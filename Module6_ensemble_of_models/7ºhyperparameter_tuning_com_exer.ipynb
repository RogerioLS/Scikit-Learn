{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Na se√ß√£o anterior, n√£o discutimos os par√¢metros de floresta aleat√≥ria e aumento de gradiente. No entanto, h√° algumas coisas que voc√™ deve ter em mente ao configur√°-los.\n",
    "\n",
    "Este bloco de notas fornece informa√ß√µes cruciais sobre como definir os hiperpar√¢metros dos modelos de √°rvore de decis√£o de aumento de gradiente e floresta aleat√≥ria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p>Por motivos de clareza, nenhuma cross-validation ser√° usada para estimar o erro de teste. Estamos apenas mostrando o efeito dos par√¢metros no conjunto de valida√ß√£o do que deveria ser a cross-validation interna.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "O par√¢metro principal para ajustar para floresta aleat√≥ria √© o par√¢metro `n_estimators`. Em geral, quanto mais √°rvores na floresta, melhor ser√° o desempenho de generaliza√ß√£o. No entanto, isso diminuir√° o tempo de adapta√ß√£o e previs√£o. O objetivo √© equilibrar o tempo de computa√ß√£o e o desempenho de generaliza√ß√£o ao definir o n√∫mero de estimadores ao colocar esse aluno em produ√ß√£o.\n",
    "\n",
    "O par√¢metro `max_depth` tamb√©m pode ser ajustado. √Äs vezes, n√£o h√° necessidade de √°rvores totalmente crescidas. No entanto, esteja ciente de que, com floresta aleat√≥ria, as √°rvores s√£o geralmente profundas, pois estamos procurando ajustar os alunos nas amostras de bootstrap, pois isso ser√° atenuado combinando-as. A montagem de √°rvores mal ajustadas (ou seja, √°rvores rasas) tamb√©m pode levar a uma floresta mal ajustada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>34.491224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>34.852569</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>35.997110</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>48.691969</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>48.719785</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>48.782024</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>56.941830</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>57.000582</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>57.337783</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_depth  mean_test_score  rank_test_score\n",
       "8                 30            None        34.491224                1\n",
       "7                 20            None        34.852569                2\n",
       "6                 10            None        35.997110                3\n",
       "4                 20               5        48.691969                4\n",
       "5                 30               5        48.719785                5\n",
       "3                 10               5        48.782024                6\n",
       "2                 30               3        56.941830                7\n",
       "1                 20               3        57.000582                8\n",
       "0                 10               3        57.337783                9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 20, 30],\n",
    "    \"max_depth\": [3, 5, None],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(n_jobs=2), param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=2,\n",
    ")\n",
    "grid_search.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que em nossa pesquisa em grade, o maior `max_depth` junto com os maiores `n_estimators` levou ao melhor desempenho de generaliza√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosting decision trees\n",
    "\n",
    "Para o aumento de gradiente, os par√¢metros s√£o acoplados, portanto, n√£o podemos mais definir os par√¢metros um ap√≥s o outro. Os par√¢metros importantes s√£o `n_estimators`, `max_depth` e `learning_rate`.\n",
    "\n",
    "Vamos primeiro discutir o par√¢metro max_depth. Vimos na se√ß√£o sobre aumento de gradiente que o algoritmo se ajusta ao erro da √°rvore anterior no conjunto. Assim, caber em √°rvores totalmente crescidas ser√° prejudicial. Na verdade, a primeira √°rvore do conjunto se ajustaria perfeitamente (superadaptaria) aos dados e, portanto, nenhuma √°rvore subsequente seria necess√°ria, uma vez que n√£o haveria res√≠duos. Portanto, a √°rvore usada no aumento de gradiente deve ter uma profundidade baixa, normalmente entre 3 a 8 n√≠veis. Ter alunos muito fracos em cada etapa ajudar√° a reduzir o sobreajuste.\n",
    "\n",
    "Com essa considera√ß√£o em mente, quanto mais profundas as √°rvores, mais r√°pido os res√≠duos ser√£o corrigidos e menos alunos ser√£o necess√°rios. Portanto, `n_estimators` deve ser aumentado se `max_depth` for menor.\n",
    "\n",
    "Finalmente, esquecemos o impacto do par√¢metro `learning_rate` at√© agora. Ao ajustar os res√≠duos, gostar√≠amos que a √°rvore tentasse corrigir todos os erros poss√≠veis ou apenas uma fra√ß√£o deles. A taxa de aprendizado permite que voc√™ controle esse comportamento. Um pequeno valor de taxa de aprendizagem corrige apenas os res√≠duos de muito poucas amostras. Se uma grande taxa de aprendizado for definida (por exemplo, 1), ajustar√≠amos os res√≠duos de todas as amostras. Portanto, com uma taxa de aprendizado muito baixa, precisaremos de mais estimadores para corrigir o erro geral. No entanto, uma taxa de aprendizagem muito grande tende a obter um conjunto superaquecido, semelhante a uma √°rvore com uma profundidade muito grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>35.664653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36.703013</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>37.458088</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.056313</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>39.354899</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.450557</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.730580</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40.602042</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41.602175</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45.588320</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45.756084</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45.863965</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>47.245184</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>47.305145</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>47.519112</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>51.961816</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>56.354543</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>62.270268</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_max_depth param_learning_rate  mean_test_score  \\\n",
       "5                  50               5                 0.1        35.664653   \n",
       "11                 50               3                   1        36.703013   \n",
       "10                 30               3                   1        37.458088   \n",
       "13                 30               5                   1        39.056313   \n",
       "4                  30               5                 0.1        39.354899   \n",
       "12                 10               5                   1        39.450557   \n",
       "14                 50               5                   1        39.730580   \n",
       "2                  50               3                 0.1        40.602042   \n",
       "9                  10               3                   1        41.602175   \n",
       "7                  30            None                 0.1        45.588320   \n",
       "1                  30               3                 0.1        45.756084   \n",
       "8                  50            None                 0.1        45.863965   \n",
       "17                 50            None                   1        47.245184   \n",
       "16                 30            None                   1        47.305145   \n",
       "15                 10            None                   1        47.519112   \n",
       "6                  10            None                 0.1        51.961816   \n",
       "3                  10               5                 0.1        56.354543   \n",
       "0                  10               3                 0.1        62.270268   \n",
       "\n",
       "    rank_test_score  \n",
       "5                 1  \n",
       "11                2  \n",
       "10                3  \n",
       "13                4  \n",
       "4                 5  \n",
       "12                6  \n",
       "14                7  \n",
       "2                 8  \n",
       "9                 9  \n",
       "7                10  \n",
       "1                11  \n",
       "8                12  \n",
       "17               13  \n",
       "16               14  \n",
       "15               15  \n",
       "6                16  \n",
       "3                17  \n",
       "0                18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 30, 50],\n",
    "    \"max_depth\": [3, 5, None],\n",
    "    \"learning_rate\": [0.1, 1],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    GradientBoostingRegressor(), param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=2\n",
    ")\n",
    "grid_search.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p>Aqui, ajustamos os n_estimators, mas esteja ciente de que usar a parada antecipada como no exerc√≠cio anterior ser√° melhor.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Exerc√≠cio M6.05\n",
    "\n",
    "O objetivo do exerc√≠cio √© familiarizar-se com o aumento de gradiente do histograma no scikit-learn. Al√©m disso, usaremos este modelo em uma estrutura de valida√ß√£o cruzada para inspecionar par√¢metros internos encontrados por meio de pesquisa em grade.\n",
    "\n",
    "Usaremos o conjunto de dados de habita√ß√£o da Calif√≥rnia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, crie um regressor de aumento de gradiente de histograma. Voc√™ pode definir o n√∫mero de √°rvores para ser grande e configurar o modelo para usar a parada antecipada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "hist_gbdt = HistGradientBoostingRegressor(\n",
    "    max_iter=1000, early_stopping=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos uma pesquisa em grade para encontrar algum par√¢metro ideal para este modelo. Nesta pesquisa em grade, voc√™ deve pesquisar os seguintes par√¢metros:\n",
    "\n",
    "* `max_depth: [3, 8]`;\n",
    "* `max_leaf_nodes: [15, 31]`;\n",
    "* `learning_rate: [0,1, 1]`.\n",
    "\n",
    "Sinta-se √† vontade para explorar o espa√ßo com valores adicionais. Crie a pesquisa em grade fornecendo a inst√¢ncia de aumento de gradiente anterior como o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": [3, 8],\n",
    "    \"max_leaf_nodes\": [15, 31],\n",
    "    \"learning_rate\": [0.1, 1],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(hist_gbdt, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, faremos nosso experimento por meio de valida√ß√£o cruzada. A este respeito, defina uma valida√ß√£o cruzada de 5 vezes. Al√©m disso, certifique-se de embaralhar os dados. Posteriormente, use a fun√ß√£o `sklearn.model_selection.cross_validate` para executar a valida√ß√£o cruzada. Voc√™ tamb√©m deve definir `return_estimator = True`, para que possamos investigar o modelo interno treinado por meio de valida√ß√£o cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "results = cross_validate(\n",
    "    search, data, target, cv=cv, return_estimator=True, n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que obtivemos os resultados da valida√ß√£o cruzada, imprima a pontua√ß√£o m√©dia e o desvio padr√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score with cross-validation:\n",
      "0.839 +/- 0.006\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "print(f\"R2 score with cross-validation:\\n\"\n",
    "      f\"{results['test_score'].mean():.3f} +/- \"\n",
    "      f\"{results['test_score'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, inspecione a entrada do `estimator` dos resultados e verifique os melhores valores dos par√¢metros. Al√©m disso, verifique a quantidade de √°rvores utilizadas pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_leaf_nodes': 15}\n",
      "# trees: 528\n",
      "{'learning_rate': 0.1, 'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "# trees: 447\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_leaf_nodes': 15}\n",
      "# trees: 576\n",
      "{'learning_rate': 0.1, 'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "# trees: 290\n",
      "{'learning_rate': 0.1, 'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "# trees: 414\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "for estimator in results[\"estimator\"]:\n",
    "    print(estimator.best_params_)\n",
    "    print(f\"# trees: {estimator.best_estimator_.n_iter_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecione os resultados do CV interno para cada estimador do CV externo. Agregue a pontua√ß√£o m√©dia do teste para cada combina√ß√£o de par√¢metros e fa√ßa um gr√°fico de caixa dessas pontua√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "import pandas as pd\n",
    "\n",
    "index_columns = [f\"param_{name}\" for name in params.keys()]\n",
    "columns = index_columns + [\"mean_test_score\"]\n",
    "\n",
    "inner_cv_results = []\n",
    "for cv_idx, estimator in enumerate(results[\"estimator\"]):\n",
    "    search_cv_results = pd.DataFrame(estimator.cv_results_)\n",
    "    search_cv_results = search_cv_results[columns].set_index(index_columns)\n",
    "    search_cv_results = search_cv_results.rename(\n",
    "        columns={\"mean_test_score\": f\"CV {cv_idx}\"})\n",
    "    inner_cv_results.append(search_cv_results)\n",
    "inner_cv_results = pd.concat(inner_cv_results, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAElCAYAAABeXh34AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de7xVdZ3/8dfbIwjeSIUaFcX7RHjBxEveJ/ulJZXOT6fspmaZjWblNOJkjvqbHMXKnLKLTVpZYWZlKWWpgZSJ5kFBRaZCAyFQsRRlxET8/P5Y3y2Lzb6sc85e56yD7+fjsR6sy/f7XZ+19mZ/zlp77e9XEYGZmVkVbTDQAZiZmTXjJGVmZpXlJGVmZpXlJGVmZpXlJGVmZpXlJGVmZpXlJGVWcZIOl7S4n/e5QtJOLbYvkPSm/ozJXpmcpKxUVfswk/RuSd3pQ3ippJslHSzphBSr6spvKOkJSRMHKuZ6/XFOI2LTiHgk7e9bkj5T5v6q6pV87FXhJGXrHWXWeW9LOgu4HPhP4DXA9sBXgHcANwCvAg6rq3YUEMAvCux3w75Fbu0MtnM82OKtpIjw5Km0CVgAvCnNnwTcAXwOeAr4E/CWXNnbgf8Afgs8C9wCjMxtPwC4E3gamAMcXlf3olR3JbBLXRwjgBXA8S1i/Tpwdd26HwCXNSl/UtrfF4C/Ap8BNkrH9yjwOPA1YHgqPxKYmuL/K/AbYIO0LfIxA98CPpPmDwcWp/nvAC+lY1wBnA0MA74L/CW1fQ/wmgbxngzclFueD/wgt7wIGJ+PBzgVWAW8kPZ3U+51/SRwP7AcuA4Y1uY8fSmV/R/giLq45qXX/BHgw7lthwOLgUnAY+n4t0jncVl6H00FRte9Fz6T3isrgJuArYDvAc+k87NDrvxrgVvTa/J74J/S+mbHvg3wo7T/PwFn5tq6APhhej2eAT4I7Ad0p+XHafJ+8tTk/+VAB+Bp/Z5YN0mtAj4EdAEfAZYASttvBx4GdgOGp+VL0rZt04fwW8nuAPyftDwqV/dRYBywITCkLo6jgBeBDVvEelD6IKkllRFkyWB8k/InpTY/mvY5nOxK7UZgS2Cz9AF5cSp/MVnSGpKmQ3LHXihJ1Z/TtPzhtJ+N03ndB9i8Qbw7kSWxDYCtgYXAn3PbnqJB0szHUhfD78g+sLckSzKntTlPn0jH/U6yZLVl2n40sDMgsivZ54DX5479RWAy2R8Aw8kSzv9Nx7sZcD3wk9z+bidLwDun1/Ah4A/Am9LrdA3wzVR2E7LkfHLa9nrgSWBco2NP524W8O/A0HTeHgGOTNsvIHuPH5PKDgdmAu9L2zcFDhjo/5eDafLtPutvCyPivyNiNfBtsg/L1+S2fzMi/hARK8muYsan9e8Ffh4RP4+IlyLiVrK/Tt+aq/utiJgbES9GxKq6/W4FPBkRLzYLLCJ+S/aX7rFp1T8Bf4iI2S2OZ0lEfCm1+zxZAv5ERPw1Ip4lu7X4rlR2VTreMRGxKiJ+E+mTq49WkR3fLhGxOiJmRcQzDY7vEbKrlfFkyeCXwJ8lvTYt/yYiXurBfr8YEUsi4q9kSXJ8i7JPAJen476O7Irl6BTXzyLi4cjMILuCPiRX9yXg/Ij4W0SsjIi/RMSPIuK5dI4vYt3btN9MbS4HbgYejojb0ut0PbB3KjcRWBAR30zvm3vJrpKOa3Ic+5L9YfT/IuKFdE7/mzWvMcDMiPhJep+uJHt9dpE0MiJWRMRdLc6T1XGSsv72WG0mIp5Ls5s22k72F3Vt2xjgeElP1ybgYLIP/ZpFLfb7F2Bkge8IrgHen+bfR5ZIW8nvcxTZX/ezcjH+Iq0H+CzZX/i3SHpE0jlt2i7qO2QJ5/uSlki6VNKQJmVnkF2dHJrmbyf7gD8sLfdEs9eqkT/XJeSFZFdhSHqLpLsk/TWds7eS3RqtWRYRz9cWJG0s6UpJCyU9A/waeJWkrlydx3PzKxss599X+9e9r94D/F2T4xgDbFNX/lOs/YdW/fvwFLK7A/8j6Z4qPYQzGDhJ2WCxCPhORLwqN20SEZfkyrS6KplJdqVzTJv9XAMcIekNZN+BTWlTPr/PJ8k+AMflYhwREZsCRMSzEfEvEbET8DbgLElHpLrPkSW4mmYfkvX7JF2dXBgRrwMOJLs6eH/DmmuS1CFpfgbtk1Qnrva2rXtycntgiaSNyK5cPkf2PdqrgJ+T3fprtv9/Af4e2D8iNidLuNTVKWoRMKPufbVpRHykyb4XAX+qK79ZROSv6Otfnz9GxAnAq8luW/5Q0ia9iPUVyUnKBovvAm+TdKSkLknD0u+HRhepnG77/DvwZUnHpL/Gh6S/4i/NlVtI9nDHtcCtEfFYkyYb7eMlsls/X5D0agBJ20o6Ms1PlLRL+rB+BlidJoDZwLvTsR3Furev8h4n+y6E1O4/SNojXUk8Q3Z7aXWTujOAfyD73m0x2cMbR5HdLryvyP566dXAmemcHw+MJUtGQ8m+a1oGvCjpLcCb27S1GdkfA09L2hI4vw9xTQV2k/S+FNsQSftKGpu21x/774BnJE2SNDy9XrtL2rfZDiS9V9Ko9P54Oq1u9vpYHScpGxQiYhHZo+KfIvtAWwT8Kz14D0fEZcBZwKdzbZwB/KSu6LfJbutc04tQJ5Hd0rsr3Yq6jeyvfoBd0/IKsiu7r0TE7Wnbx8iurmq3m+pjyrsY+HS63fRJsquuH5IlqHlkiei7jSpGxB/S/n+Tlp8h++L/t+l7wkauAl6X9tcqrlbuJjv+J8m+Qzoufbf0LHAm2fePTwHvJnvwpJXLyR5IeBK4iwI/D2gm7f/NZN8pLSG7hVl7SAPqjj2do7eRff/2pxTDN8ge0GjmKGCupBXAfwHvyt++tNZqTxaZmZVC0knAByPi4IGOxQYfX0mZmVllOUmZmVll+XafmZlVlq+kzMysspyk1mOSLpb08YGOo5kye5iWdIGkhk+4DQad6uk8PSZ9k6Tlkq7vRGwF9ln60CID+fpKmivp8IHYd6dIukzSaQMdRxFOUuspSaPIftB55UDHUrb++FAcxI4j6w1hq4g4fqCDWR9ExLjcTwcqQdLtkj7YgyqfBc6VNLSsmDrFSWr9dRJZX3crBzoQG1BjyPofbNpnoa1RxaE1yogpIpaS9Ub/9k633WlOUuuvt5Dr5qZ2tSHpbGWD+C1NPS+8VdIfUr9pn8qV30/SzPQjxqWSrqj91SXpQElPStouLe+Vyr22VUCS9pZ0r6RnJV1HNsREfvtESbNTW3dK2jO3bYGkf5P0kKSnJH0z9TqxCVkHotsoG8hwhaRtUrWhkq5J+5sraUKRE1eFc1UXzwaSzpH0sKS/SPpB6mmhtv16SY+lW3q/ljQurb+QrJeNd6bzckqLfZwk6Q5Jn0vn90/Ken+obd9G0o3p2OdL+lBu2/B06/YpSQ+RdcJKXd0fSVqW2j2z7tx1S3pG0uOSLit6Xur2cUB6zzwtaU7+dpykkyXNS++DRyR9OLet9lpPkvQY8E1ltxJ/0Oy9o9yt2AJlXy/pvrTteknXqc0t7iYxbSFpajqHT6X50an8RWTdXF2RXucr0vrXSro1vWa/l/RPdbu6ndTJb6U16hrd0+CfyHpU2De3fDjZkAf/TjZcwodSmSlk3cyMI+vbbqdUfh+yvus2BHYg68ng47n2LgKmkf3y/37gjDbxDCXrVLQ2XMNxZN331IajeD1ZT9n7kw03cSLZcBAbpe0LgAeB7ciGhvgtTYaySOsuSMfz1tTexcBdBc/dgJ6r3PHWhjj5OFnPCqPJekK4Erg2V/YDKa6NyHpjmF13Hr5bYH8n0XoYlRlkA0QOI+ttYRlpTCjgErIeLLZMr8+DrBn/qt3QFr0axiJ/XLQfxqWnQ4G0fO/UvTZNy7LmPf8xsvfRP5KNTfWZNsfWKKYiw5N8MLfccgiSVOYfgXsH+rOq7Ws90AF4KumFzT5wXptbPpysv7OutLwZWUeY++fKzAKOadLex4EbcstDUvkHyLqlUZt4DiX3oZfW3cmaRPNV4D/q6vweOCzNLyA3XlH6UHg4d2yNktRtueXXASsLnrsBPVe54619EM5j7UECt06v7zpjY5GNLhzAiNx5KJqk5ueWN07t/B1Z4lkNbJbbfjHZ0CiQJZ2jcttOZU2S2h94tG5f/8aa8Zx+DVxIbnDLgq/Ry8dF1hXVd+q2/xI4sUndnwAfy73WL5AbsLHde4d1k1TDsmTv+T+z9nv+DoolqbVialBmPPBUbvl21k5S7yQbeiVf50qyIU9qy/8HeKQn530gJt/uW389RfbhmveXWNM/W+27qoZDGEjaLd1SeExZH3T/SW74hMjGa/oWsDvw+Ujv+ha2ofFwDTVjgH/R2kMgbJfq1Syqq5vf1kj9UBLDVPz+/kCeq3pjgBty52UeWdJ4jbIOTi9JtwKfIfsAhbWHuiiq2TAq2wC18bFqFpJdwZC21782+dhbDW3RiWEsWg7joh4OBZL05L3TrGyj93yr4WTyejM8SV6RIUg2Y02Ht5XlJLX+up/sP39vfZXsi9VdIxsO4VPkhkKQtC1Z79PfBD6vbMiFVpbSeLiGmkXARbH2EAgbR8S1uTLb1dVdkuYH+hfpnT5X9RYBb6k7N8Mi4s9kHbK+g2zU2RFktxvJ778DlgBbSsr/0bM92VUCZK9t/WuTj/1P0WRoi+jMMBZNh3FR74YC6ZRG7/ntmhWu09PhSRoNKdJqCBLIeqKfUzCeAeMktf76Oa2He2hnM7JetVco+5L/5Td3+k/3LbIeok8h+8/4H23am0l2n/1MSRtK+kdgv9z2/wZOk7S/MptIOrrug/F0SaOVPTTwKeC6tP5xYCtJrXqiXouyL/q/VbR8G50+V/W+BlwkaUxqc5Skd+T2/Tey72A2JruK66jIeqC/E7hY2cMqe5Idy/dSkR8A/5a+3B8NfDRXveXQFmoxjEV6QOGkAiG2GsalN0OBdMpMsmM5I73n38Ha7/meaDc8Sf2QIu2GIIHs8+HmXsbTb5yk1l/XAG+VNLyX9T9J9lf6s2QJ5LrctjPJbtecl25lnAycLOmQdVpJIuIFsi9qTyK7FflO4Me57d1kX9pfkbbPT2XzppANLf5Imj6T6v4P2fhPj6RbG+1uA0L2F+1vC5QroqPnqoH/Ihu+4hZJz5I9RLF/2nYN2e21PwMPpW1lOIHsKm0JcAPZdxu3pm0Xphj+RPb6fKdWKdoPbdFwGAtlT0duVeR4osUwLtG7oUA6IveeP4UsAb+XLHn8rRfNtRue5L+A49KTf1+MNkOQSNqa7Puz3g690m/cd996TNJ/Ak9ExOUDHUtfSVpA9sXwbR1oayjZbY490/dFVjGSDgZOT7cC1xuS7ga+FhHfHOA4Pk/24NFXBjKOIpykbFDoZJIy6y+SDiN7SvVJsgcXvkb204WlAxrYIOLbfdYxkrbXmh/U1k/bt2/hlWMgzpWkrzXZ39fK2J8B2cMOc4DlZA8/HBcRSyV9qslrUfnviPqbr6TMzKyyfCVlZmaVVbnOFAe7kSNHxg477DDQYZiZDRqzZs16MiJGNdrmJNVhO+ywA93d3QMdhpnZoCFpYbNtvt1nZmaV5SRlZmaV5SRlZmaV5SRlZmaV5SRlZmaV5af7BqG9LryF5Stbdzm3cPJExkya2qf9jBg+hDnn91eH0WZm63KSGoSWr1zFgkuObllGk2lbpp0dzvlZn+qbmfWVb/eZmVllOUmZmVlllZak0iicMyR1peVLJc2VNE/SF+uGVG5U/zRJD0iaLekOSa/LbftFGtyu0Jcukg6VdK+kFyUd16LcPmmf8/MxSjpD0snFjrz32pySAVXl2Mxs/VXmldQHgB9HxGpJBwIHAXsCuwP70n5o8ykRsUdEjAcuBS7Lbfss8L4exPIo2SivU9qU+ypwKrBrmo5K668mG93TzMz6UZlJ6j3AT9N8AMOAoWTDFw8BHm9VOSKeyS1uktqobfsV2VDdhUTEgoi4H3ipWZk0nPLmETEzDfN9DXBMqv8csEDSfkX3aWZmfVfK031peO6dImIBQETMlDQdWAoIuCIi5hVo53TgLLLk9sYyYs3ZFlicW16c1tV0A4cAv6uvKOlUsiswtt++b+PVFb6tdkn544AtnDwRTS59N2ZmTZV1JTUSeLq2IGkXYCwwmuyD/42SDm3XSER8OSJ2BiYBny4p1ppG2SGfCZ4AtmlUMSK+HhETImLCqFENe5svLCLaTn39/VNRYyZNfXmfZmYDoawktZLs9l7NscBdEbEiIlYANwMH9KC975NuvZVoMVkSrRkNLMktDyM7LjMz6yelJKmIeAroklRLVI8Ch0naUNIQsocm5gFIuljSsfVtSNo1t3g08Md2+23WVsGYlwLPSjogPdX3ftZ8pwawG/Bgb9o2M7PeKfPBiVuAg9P8D4GHgQeAOcCciLgpbdsDeKxB/TPSI+uzyb6XOrG2QdJvgOuBIyQtlnRkq7Yk7StpMXA8cKWkublts3NFPwJ8A5if4r05t+0g4LYiB95bVb6tVuXYzGz9VWa3SFeQJZfbImI18OEm5YZExMz6lRHxsWYNR8QhPWzrHta+lZffNj433032iPxaJO0NzI2IJ5vFZGZmnVfalVRE3AdMr/2Yt0W5I1tt7+E+O9ZWnZHAeSW1bWZmTZTawWxEXF1m+/0lIm4d6BjqFen8ta8dxI4YPqRP9c3M+sq9oA9ChXo374ffUZmZlc0dzJqZWWU5SZmZWWU5SZmZWWU5SZmZWWU5SZmZWWU5SZmZWWU5SZmZWWU5SZmZWWU5SZmZWWU5SZmZWWU5SZmZWWW57z57RdjrwltYvnIVCydPZMykqT2qO2L4EOac/+aSIjOzVpyk7BVh+cpVLLjkaDS5YAe9OX3tTd7Mes+3+8zMrLKcpMzMrLJKS1KShkuaURuZV9KlkuZKmifpi5LUpv6hku6V9KKk4+q2rZY0O003FoilaVt15faR9ICk+fkYJZ0h6eRiR2591eatUUmDMWazwaDMK6kPAD+OiNWSDgQOAvYEdgf2BQ5rU/9R4CRgSoNtKyNifJreXiCWVm3lfRU4Fdg1TUel9VcDZxbYj5mZdVCZSeo9wE/TfADDgKHARsAQ4PFWlSNiQUTcD7zU10CKtCVpa2DziJgZEQFcAxyT6j8HLJC0X19jMTOz4kpJUpKGAjtFxAKAiJgJTAeWpumXETGvD7sYJqlb0l2SjulzwJltgcW55cVpXU03cEijipJOTfF0L1u2rEPhvLJJ6ui0cPLEXseycPLEtu2bWTnKupIaCTxdW5C0CzAWGE32wf9GSYf2of3tI2IC8G7gckk79yXYWpgN1kVu/glgm0YVI+LrETEhIiaMGjWqA6FYRHR06ulvo/LGTJratn0zK0dZSWol2e29mmOBuyJiRUSsAG4GDuht4xGxJP37CHA7sHfvQ33ZYrIkWjMaWJJbHkZ2XGZm1k9KSVIR8RTQJamWqB4FDpO0oaQhZA9NzAOQdLGkY4u2LWkLSRul+ZFkD2Q81Ju26mJeCjwr6YD0VN/7WfOdGsBuwIO9advMzHqnzAcnbgEOTvM/BB4GHgDmAHMi4qa0bQ/gsfrKkvaVtBg4HrhS0ty0aSzQLWkO2fdcl0TEQ71sC0mzc0U/AnwDmJ/ivTm37SDgtoLHbmZmHVBmt0hXAGcBt0XEauDDTcoNSQ9WrCUi7mHt22+19XeSJaM+t5W2jc/Nd5M9Ir8WSXsDcyPiySb7tQ4ajN/xDMaYzQaD0q6kIuI+YHrtx7wtyh3ZwX12rK06I4HzSmrbzMyaKLWD2Yi4usz2+0tE3DrQMVjf1TqK7WmHsSOGDykjHDMrwL2g2yvCyz2fX+LbcmaDiTuYNTOzynKSMjOzynKSMjOzynKSMjOzynKSMjOzynKSMjOzynKSMjOzynKSMjOzynKSMjOzynKSMjOzynKSMjOzynKSMjOzynIHs2YdtNeFt7B85ape1V04eSJjJk3taDwjhg9hzvlv7mibZv3JScqsg5avXLWmx/Ue0mR6XbeZng5LYlY1vt1nZmaV5SRl1oakgQ6h0nx+rEylJSlJwyXNkNQlaYykWZJmS5or6bQC9U+T9ECqc4ek1+W2/ULS05IK3cCXdKikeyW9KOm4FuX2SfucL+mLSv/7JJ0h6eQi+zIzs84p80rqA8CPI2I1sBQ4MCLGA/sD50japk39KRGxR6pzKXBZbttngff1IJZHgZOAKW3KfRU4Fdg1TUel9VcDZ/Zgf2Zm1gFlJqn3AD8FiIgXIuJvaf1GRfYbEc/kFjcBIrftV8CzRQOJiAURcT/wUrMykrYGNo+ImRERwDXAMan+c8ACSfs1qXuqpG5J3cuWLSsalg0ikgpNCydPHOhQ17Jw8sTCsfd2MitTKUlK0lBgp4hYkFu3naT7gUXA5IhYUqCd0yU9THYlVfaVzLbA4tzy4rSuphs4pFHFiPh6REyIiAmjRo0qMUQbKBFRaOr0I+R9NWbS1MKx93YyK1NZV1IjgafzKyJiUUTsCewCnCjpNe0aiYgvR8TOwCTg06VEukajPwnz/wOfANrdojQzsw4qK0mtBIY12pCuoObS5Kqkie+Tbr2VaDEwOrc8Gshf7Q0jOy4zM+snpSSpiHgK6JI0DEDSaEnD0/wWwEHA79PyxZKOrW9D0q65xaOBP7bbb7O2Csa8FHhW0gHpqb73k75TS3YDHuxN22Zm1jtlPjhxC3Bwmh8L3C1pDjAD+FxEPJC27QE81qD+Gelx9dnAWcCJtQ2SfgNcDxwhabGkI1u1JWlfSYuB44ErJc3NbZudK/oR4BvAfOBh4ObctoOA2wodua1X/L1Laz4/VqYyu0W6giy53BYRtwJ7Nik3JCJm1q+MiI81azgimt0qbNbWPax9Ky+/bXxuvhvYvb6MpL2BuRHxZLOYzMys80pLUhFxn6TpkrrSb6WalTuy2bZe7LNjbdUZCZxXUtu2nulLf3md7mtvxPAhHW3PrL/Jl+qdNWHChOju7h7oMMzMBg1JsyJiQqNt7rvPzMwqy0nKzMwqy0nKzMwqy0nKzMwqy0nKzMwqy0nKzMwqq1CSkrSzpI3S/OGSzpT0qnJDMzOzV7qiV1I/AlZL2gW4CtiR9gMImpmZ9UnRJPVSRLwIHAtcHhGfALYuLywzM7PiSWqVpBPIOnmtjerm/lbMzKxURZPUycAbgIsi4k+SdgS+W15YZmZmBTqYldQFfCoi3ltbFxF/Ai4pMzAzM7O2SSoiVksaJWloRLzQH0GZDVZ7XXgLy1eu6lXdhZMnMmbS1PYFe2DE8CHMOf/NHW3TrD8VHapjAfBbSTcC/1tbGRGXlRGU2WC1fOUqFlxydK/qajK9rttMp4f+MOtvRZPUkjRtAGxWXjhmZmZrFEpSEXEhgKRNIuJ/25U3W59I8hDpLfj8WJmK9jjxBkkPAfPS8l6SvtKmznBJMyR1SRojaZak2ZLmSjqtwD4PlXSvpBclHVe3bXVqa3a6BdnrturK7SPpAUnzJX1RktL6MySd3G4/ZmbWWUUfQb8cOBL4C0BEzAEObVPnA8CP09DxS4EDI2I8sD9wjqRt2tR/FDiJxj1brIyI8Wl6e4H4W7WV91XgVGDXNB2V1l8NnFlgP2Zm1kFFv5MiIhalC4ua1W2qvAd4d6qbfypwIwokx4hYACDppaIx9qUtSVsDm0fEzLR8DXAMcHNEPCdpgaT9IuJ3DeqeSpbc2H777fsarlVQ3Xu/tUuqc+tr4eSJaPJAR2HWe0WvpBZJOhAISUMlfZJ0668RSUOBnWrJIa3bTtL9wCJgckQs6UPcwyR1S7pL0jF9aCdvW2BxbnlxWlfTDRzSqGJEfD0iJkTEhFGjRnUoHKuSiCg0dfoR8r4aM2lq4dh7O5mVqWiSOg04nTUf5OOBf25RfiTwdH5FRCyKiD2BXYATJb2m5+G+bPuImEB2pXa5pJ370FZNoz+V8/8DnwDa3aI0M7MOKpqk/j4i3hMRr4mIV6feJ8a2KL8SGNZoQ7qCmkuTq5IialdhEfEIcDuwd2/bylkMjM4tjyZ77L5mGNlxmZlZPymapL5UcB0AEfEU0CVpGICk0ZKGp/ktgIOA36fliyUdWzRgSVvkxrYamdp6qDdt1cW8FHhW0gHpqb73Az/NFdkNeLA3bZuZWe+0fHBC0huAA4FRks7Kbdoc6GrT9i3AwcBtZFddn5cUZLfVPhcRD6RyewDrPEYuaV/gBmAL4G2SLoyIcamtK9NDEBsAl0TEQ71sC0mz01OHAB8BvgUMB25OU81BwIVtjtnWQ/7epTWfHytTu6f7hgKbpnL5niaeAZr+3ii5AjgLuC0ibgX2bFJuSO2JuryIuIe1b7/V1t9Jloz63FbaNj433w3sXl9G0t7A3Ih4ssl+zcysBC2TVETMAGZI+lZELOxJjxMRcZ+k6ZK60m+lmpU7socxt9pnx9qqMxI4r6S2bT3Tl/7yOt3X3ojhHvbNBjcVuVRPt/2uAjaNiO0l7QV8OCJaPeH3ijRhwoTo7u4e6DDMzAYNSbPSE9vrKLPHCTMzsz4pmqSIiEV1q9r1OGFmZtYnRbtFWqvHCbJ+7Jr2OGFmZtYJfelx4vSygjIzM4Pi40k9SdZhrJmZWb8plKQk7Qh8FNghX6fgMBlmZma9UvQ7qZ+QPYJ+E9DnoTPMzMyKKJqkno+IL5YaiZmZWZ2iSeq/JJ1P1h/f32orI+LeUqIyMzOjeJLaA3gf8EbW3O6LtGxmZlaKoknqWLKRdl9oW9LMzKxDiv5Oag7wqjIDMTMzq1f0Suo1wP9Iuoe1v5PyI+hmZgNEEmMmTWXE8CHMOf/NAx1OKYomqfNLjcLMzHplwSVHd3yIlyop2uPEjLIDMTMzq1foOylJB0i6R9IKSS9IWi3pmbKDMzOz9hZOnjjQIZSm6IMTVwAnAH8EhgMfTOuakjRc0gxJXWn5UklzJc2T9EVJalP/NEkPSJot6Q5Jr8tt+4WkpyVNLRK8pI0kXSdpvqS7Je3QpNxFkhZJWlG3/gxJJxfZl5lZb1x77bXsvvvudHV1sfvuu3PttdcOSBuVExFtJ6A7/Xt/bt2dbeqcDnwszR8I/BboStNM4PA29TfPzZDWNGwAABXoSURBVL8d+EVu+QjgbcDUgvH/M/C1NP8u4Lom5Q4AtgZW1K3fGLivyL722WefMDPriSlTpsSOO+4Y06ZNixdeeCGmTZsWO+64Y0yZMqVlvewjPPu3t21UQS3HNJqKJqlfA0OBa4BLgU8Ac9rUuRPYIc2/AZhFdhW2MdANjC2y71T/BODmunWH9yBJ/RJ4Q5rfEHgSUIvyKxqsuwHYr92+nKTMrKfGjRsX06ZNW2vdtGnTYty4cS3r5ZNUb9uoglZJStn21iSNAR5PieoTwAjgKxExv0n5ocCjEfF3uXWfI7tNKOCKiDi3wH5PB85K+31jRPwxt+1w4JMR0fZmrKQHgaMiYnFafhjYP7IhSBqVXxERm9atO5esD8PPNyh/KnAqwPbbb7/PwoUL24VkZvayrq4unn/+eYYMGfLyulWrVjFs2DBWr24+CLqk7INcYoMNNuhVG1UgaVZETGi0re13Uuk7pYsi4vmIeCYiLoyIs5olqGQk8HSujV2AscBosoET3yjp0Hb7jogvR8TOwCTg0+3KtzqMRs33sI0ngG0abYiIr0fEhIiYMGrUqB4HZ2avbGPHjuWOO+5Ya90dd9zB2LFj+7WNKmqbpCJiNTAqXR0VtRIYlls+FrgrIlZExArgZrLvf4r6PnBMD8rXWwxsByBpQ7Irwb/2sI1hZMdlZtZR5557LqeccgrTp09n1apVTJ8+nVNOOYVzz217w6mjbVRR0R/zLgB+K+lG4H9rKyPiskaFI+IpSV2ShkXE88CjwIckXUx2VXMYcDlAWve7iLgh34akXXO3944me7KwpWZtATcCJ5I9sHEcMC2K3Odc225kD3+YmXXUCSecAMBHP/pR5s2bx9ixY7noooteXt9fbVRR0SS1JE0bAJsVrHMLcDBwG/BDsh7THyC7zfaLiLgplduDLInUO0PSm4BVwFNkSQYASb8BXgtsKmkxcEpE/LJFW1cB35E0n+wK6l25tmZHxPg0fynwbmDj1O43IuKCVPQg4MKCx25m1iMnnHBCrxPKmElT+9xGVRXtcaI3H85XkD30cFu6ZfjhJuWGRMTMBvv8WIt4DulhW88Dxzdpa3xu/mzg7PoykvYG5jZ70MLMzMpRKElJGkX24T2O3HdNEdF0PKmIuE/SdEldKUk1K3dkD+JtqZNt1RkJnFdS22ZmvbbDOT9jxPAh7QsOUkVv930PuA6YCJxGduttWbtKEXF170Orjoi4daBjMDOr1/Ov1gefot0ibRURVwGrImJGRHyAnj2dZ2Zm1mNFr6RWpX+XSjqa7CGK0eWEZGZmlimapD4jaQTwL8CXgM3Jep4wMzMrTcskJWkY2XdQu5D1FHFVRPxDfwRmZmbW7jupbwMTyH7f9BZgnX7rzMzMytLudt/rImIPAElXAb8rPyQzM7NMuyup2gMTRMSLJcdiZma2lnZXUnvlhokXMDwti2wck81Ljc7MzF7RWiapiOjqr0DMzMzqFf0xr5mZWb9zkjIzs8pykjIzs8oq2uOEmZkNUntdeAvLV65i4eSJL489VTNi+BDmnP/mAYqsPScpM7P13PKVq1hwydFoMiy45Oi1tu1wzs8GKKpifLvPzMwqS6+E8Uj604QJE6K7u3ugwzAze5kkIuLlfxttG0iSZkXEhEbbSruSkjRc0gxJXWn5UklzJc2T9EVJalP/UEn3SnpR0nF121ZLmp2mGwvEspGk6yTNl3S3pB2alLtI0iJJK+rWnyHp5Hb7MTPrpGuvvZbdd9+drq4udt99d6699tqBDmkdpccYEaVMwOnAx9L8gcBvga40zQQOb1N/B2BP4BrguLptK3oYyz8DX0vz7wKua1LuAGDr+vaBjYH7iuxrn332CTOzvpoyZUrsuOOOMW3atHjhhRdi2rRpseOOO8aUKVN63Fb2Ub/m30bbBjJGoDuafX4329DXCbgT2CHNvwGYBQxPH/jdwNiC7XyrA0nql8Ab0vyGwJOkW51Nyq/TPnADsF+7fTlJmVknjBs3LqZNm7bWumnTpsW4ceN63FZZSapTMbZKUqXc7pM0FNgpIhaQnYGZwHRgaZp+GRHz+rCLYZK6Jd0l6ZgC5bcFFqVYXgSWA1v1cJ/dwCGNNkg6NcXTvWzZsh42a2a2rnnz5nHwwQevte7ggw9m3ry+fHR2Vn/EWNZ3UiOBp2sLknYBxpINOb8t8EZJh/ah/e0j+5Lt3cDlknZuU77R9189/abwCWCbRhsi4usRMSEiJowaNaqHzZqZrWvs2LHccccda6274447GDt27ABFtK7+iLGsJLUSGJZbPha4KyJWRMQK4Gay7396JSKWpH8fAW4H9m5TZTGwHYCkDYERwF97uNthZMdlZla6c889l1NOOYXp06ezatUqpk+fzimnnMK555470KG9rD9iLOXHvBHxlKQuScMi4nngUeBDki4mu6o5DLgcIK37XUTcUKRtSVsAz0XE3ySNBA4CLm3T1o3AiWQPbBwHTEv3QXtiN7KHP8zMSnfCCScA8NGPfpR58+YxduxYLrroopfXV0G/xNjsy6q+TsBVwJvSfBdwJTAPeAi4LFduKumhhrr6+5JdAf0v8Bdgblp/INlw9nPSv6cUaGsYcD0wn2x04Z1y22bn5i9N+3wp/XtBbtu9wMh2x+0HJ8ysasZMmhoRjR+SqG0bSLR4cKLMbpGuAM4CbouI1cCHm5QbEtmDFWuJiHvIvsOqX38nsEcP23oeOL5RhYgYn5s/Gzi7voykvcmS5JNN9mtmZiUo7ce8EXEfML32Y94W5Y7s4D471ladkcB5JbVtZmZNlNrBbERcXWb7/SUibh3oGMzM+qLWkWx9h7Ijhg8ZiHAKcy/oZmbruZd7Pr9k8PXV6l7QzcysspykzMysspykzMysspykzMysspykzMysspykzMysspykzMysspykzMysspykzMysspykzMysspykzMysstx3n5lZP9rrwltYvnJV6ftZOHkiYyZNXWvdiOFDmHP+m0vfdyc5SZmZ9aPlK1et6fC1RJrMOvup7wF9MPDtPjMzqywnKTMzq6zSkpSk4ZJmSOqSNEbSLEmzJc2VdFqB+qdJeiDVuUPS63LbfiHpaUlTW7WRK7+RpOskzZd0t6QdmpS7SNIiSSvq1p8h6eQi+zIzkzTQIXREFY6jzCupDwA/jojVwFLgwIgYD+wPnCNpmzb1p0TEHqnOpcBluW2fBd7Xg1hOAZ6KiF2ALwCTm5S7CdivwfqrgTN7sD8zM+uAMpPUe4CfAkTECxHxt7R+oyL7jYhncoubAJHb9ivg2R7E8g7g22n+h8ARavAnQkTcFRFLG6x/DlggqVECMzOzkpSSpCQNBXaKiAW5ddtJuh9YBEyOiCUF2jld0sNkV1J9uZLZNu2XiHgRWA5s1cM2uoFDmsR5qqRuSd3Lli3rQ5hmtr6Q1HBaOHnigMW0cPLEpnE1mqqgrCupkcDT+RURsSgi9gR2AU6U9Jp2jUTElyNiZ2AS8Ok+xNPobEeDda08ATS8RRkRX4+ICRExYdSoUT0OzszWPxHRcKr/7VJ/GjNpatO4Gk1VUFaSWgkMa7QhXUHNpclVSRPfB47pQzyLge0AJG0IjAD+2sM2hpEdl5mZ9ZNSklREPAV0SRoGIGm0pOFpfgvgIOD3afliScfWtyFp19zi0cAf2+23WVvAjcCJaf44YFr0/M+E3YAHe1jHzMz6oMwHJ24BDk7zY4G7Jc0BZgCfi4gH0rY9gMca1D8jPa4+GziLNUkGSb8Brid7AGKxpCPbtHUVsJWk+amtc3Jtzc7NXyppMbBxaveCXBsHAbcVO3QzeyWryq2yvqrCcZTZLdIVZAnhtoi4FdizSbkhETGzfmVEfKxZwxHR7FZhs7aeB45v0tb43PzZwNn1ZSTtDcyNiCebxWRmZp1X2pVURNwHTJfU1abcka2293CfHWurzkjgvJLaNjOzJkrtYDYiri6z/f6SrgTNzDqivzp6rd/PiOFD+mW/neRe0M3M+lF/9IAOwCUD/31SJ7iDWTMzqywnKTMzqywnKTMzqywnKTMzqywnKTMzqywnKTMzqywnKTMzqywnKTMzqywnKTMzqywnKTMzqywnKTMzqyz33Wdm1o/2uvAWlq9cVfp+Fk6euM5Q9SOGD2HO+W8ufd+d5CRlZtaPlq9c1S+dzGryup3Z9lfv653k231mZlZZTlJmZlZZTlJmZh0maaBD6IgqHEdpSUrScEkzJHVJGiNplqTZkuZKOq1A/UMl3SvpRUnH1W1bndqaLenGAm1tJOk6SfMl3S1phyblLpK0SNKKuvVnSDq53X7MzKyzyryS+gDw44hYDSwFDoyI8cD+wDmStmlT/1HgJGBKg20rI2J8mt5eIJZTgKciYhfgC8DkJuVuAvZrsP5q4MwC+zEzsw4qM0m9B/gpQES8EBF/S+s3KrLfiFgQEfcDL3UglncA307zPwSOUIPr2Ii4KyKWNlj/HLBAUqMEhqRTJXVL6l62bFkHwjWzwU5Sw2nh5IkDFtPCyRObxtVoqoJSkpSkocBOEbEgt247SfcDi4DJEbGkD7sYlpLCXZKOKVB+27RfIuJFYDmwVQ/32Q0c0mhDRHw9IiZExIRRo0b1sFkzWx9FRMOp/rdL/WnMpKlN42o0VUFZv5MaCTydXxERi4A9022+n0j6YUQ83sv2t4+IJZJ2AqZJeiAiHm5RvtGfBD19BZ4AXtvDOmZm1gdl3e5bCQxrtCFdQc2lyVVJEbWrsIh4BLgd2LtNlcXAdgCSNgRGAH/t4W6HkR2XmZn1k1KSVEQ8BXRJGgYgabSk4Wl+C+Ag4Pdp+WJJxxZtW9IWkjZK8yNTWw+1aetG4MQ0fxwwLXp+Lbsb8GAP65iZWR+U+eDELcDBaX4scLekOcAM4HMR8UDatgfwWH1lSftKWgwcD1wpaW6ure7U1nTgkoh4qFVbwFXAVpLmA2cB5+T2Mzs3f2na58aSFku6INfGQcBthY/ezF6xqvJ9Tl9V4TjK7LvvCrKEcFtE3Ars2aTckIiYWb8yIu4BRjdYfydZMupJW8+TJbt1pMfia/NnA2fXl5G0NzA3Ip5ssl8zMytBaUkqIu6TNF1SV/qtVLNyR3Zwnx1rq85I4LyS2jazV5j+6ui1fj8jhg/pl/12kqpwObc+mTBhQnR3dw90GGZmg4akWRExodE2991nZmaV5SRlZmaV5SRlZmaV5SRlZmaV5SRlZmaV5af7OkzSMmDhQMfRwEhgMP3Oy/GWy/GWy/H2zJiIaNg7t5PUK4Sk7maPeFaR4y2X4y2X4+0c3+4zM7PKcpIyM7PKcpJ65fj6QAfQQ463XI63XI63Q/ydlJmZVZavpMzMrLKcpMzMrLKcpAYhSUdJ+r2k+ZLOabD9cEnLJc1O07/nti2Q9EBa351bv6WkWyX9Mf27xUDHK+nvc+tmS3pG0sfTtgsk/Tm37a39FW8u5tmS5kqa0a7uQJ7fZvFK2i4NpzMvrf9YrnxVz2/l3r/N4h2o92+RmCX9a27fD0paLWnLVnXLPMctRYSnQTQBXcDDwE7AUGAO8Lq6MocDU5vUXwCMbLD+UuCcNH8OMLkK8da18xjZj/4ALgA+OUDn91XAQ8D2afnV7eoO8PltFu/WwOvT/GbAH3LxVu78Vvj92zTe/n7/Fo25rvzbgGkD9R5uN/lKavDZD5gfEY9ExAvA94F3dKDddwDfTvPfBo7pQJvQuXiPAB6OiLJ78ygS77uBH0fEowAR8USBugN5fhvGGxFLI+LeNP8sMA/YtkNxdTzeNip3fuv01/sXev5/7gTg2gJ1yzrHLTlJDT7bAotyy4tp/MHyBklzJN0saVxufQC3SJol6dTc+tdExFLIPryAV1ck3pp3seY/Us0Zku6XdHUHbz0UiXc3YAtJt6fz+P4CdQfy/DaL92WSdgD2Bu7Ora7a+YVqvn/bnl/67/0Lxf/PIWlj4CjgRwXqlnWOW3KSGnzUYF397wjuJbutsBfwJeAnuW0HRcTrgbcAp0s6tJwwX9bXeJE0FHg7cH1u9VeBnYHxwFLg8/0Y74bAPsDRwJHAeZJ2K1i30/oSb9aAtCnZh9THI+KZtLqK5xeq+f5td3778/1bNOaatwG/jYi/9qJuv3CSGnwWA9vllkcDS/IFIuKZiFiR5n8ODJE0Mi0vSf8+AdxAdnkP8LikrQHSv0VusZQeb/IW4N6IeDxX5/GIWB0RLwH/nTuO0uNNZX4REf8bEU8Cvwb2alN3wM5vi3iRNIQsQX0vIn5cq1DR81vJ92+reJP+fP8Wjbmm/gpvIN7DLTlJDT73ALtK2jH9hfYu4MZ8AUl/J0lpfj+y1/kvkjaRtFlavwnwZuDBVO1G4MQ0fyLw04GON1ckf8+8Vmfr3OKxueMoPV6yc3OIpA3T7ZL9yb7PaVV3wM5vs3jTOb8KmBcRl+UrVPH8VvX92yze3Pb+fP8WjRlJI4DDWPtcDcR7uLX+eDrDU2cn4K1kT2I9DJyb1p0GnJbmzwDmkj2ZcxdwYFq/U1o3J20/N9fmVsCvgD+mf7cc6HjTto3JEtaIuja/AzwA3E/2n2fr/oo3Lf8r2RNdD5LdJmtad6DPb7N4gYPJbuXcD8xO01uren6r+v5t837o9/dvD2I+Cfh+kbpln+NWk7tFMjOzyvLtPjMzqywnKTMzqywnKTMzqywnKTMzqywnKTMzqywnKbMKSr1S13qovknSq9L68ZJmKutt+35J7xzoWM3K5EfQzSpI0oqI2DTNfxv4Q0RclLrbiYj4o6RtgFnA2Ih4uuR4uiJidZn7MGvEV1Jm1TeT1MlnRPwhIv6Y5peQdU0zqr6CpDMlPZSutr6f1m0q6ZvKxmO6X9L/TetPSOselDQ518YKSf9P0t1kHQC/V9Lv0hXelZK6yj90e6VzkjKrsJQIjqBxtzb7kY3583CDqucAe0fEnmQ9DQCcByyPiD3S+mnpamwy8Eayzk73lVQbgmET4MGI2J+s14R3knXwOh5YDbynQ4dp1pSTlFk1DZc0myw5bAncmt+Y+n77DnByZJ2U1rsf+J6k9wIvpnVvAr5cKxARTwH7ArdHxLKIeBH4HlDrWXw1a4ZwOIKsp+97UlxHkHVTZFYqJymzalqZrljGkF0tnV7bIGlz4GfApyPirib1jyZLSPsAsyRtSDYMQ/2X0I2GZqh5Pvc9lIBvR8T4NP19RFzQ04My6yknKbMKi4jlwJnAJyUNST1T3wBcExHXN6ojaQNgu4iYDpxNNrz5psAtZJ351sptQTbI4WGSRqZbiycAMxo0+yvgOEmvTnW3lDSmU8dp1oyTlFnFRcR9ZD1/vwv4J7LbcSelBxhmSxpfV6UL+K6kB4D7gC+kp/8+QzaC7IOS5gD/ENkIq/8GTE/7uDci1hmCISIeAj5NNiru/WS3H7euL2fWaX4E3czMKstXUmZmVllOUmZmVllOUmZmVllOUmZmVllOUmZmVllOUmZmVllOUmZmVln/H5n7AvjZKQv7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color = {\"whiskers\": \"black\", \"medians\": \"black\", \"caps\": \"black\"}\n",
    "inner_cv_results.plot.box(vert=False, color=color)\n",
    "plt.xlabel(\"R2 score\")\n",
    "plt.ylabel(\"Parameters\")\n",
    "_ = plt.title(\"Inner CV results with parameters\\n\"\n",
    "              \"(max_depth, max_leaf_nodes, learning_rate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que os primeiros 4 conjuntos de par√¢metros classificados est√£o muito pr√≥ximos. Podemos selecionar qualquer uma dessas 4 combina√ß√µes. Ele coincide com os resultados que observamos ao inspecionar os melhores par√¢metros do CV externo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
