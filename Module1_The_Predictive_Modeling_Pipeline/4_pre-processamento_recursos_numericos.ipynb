{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento para recursos numéricos\n",
    "\n",
    "Neste notebook, ainda usaremos apenas recursos numéricos.\n",
    "\n",
    "Apresentaremos esses novos aspectos:\n",
    "\n",
    "* um exemplo de pré-processamento, nomeadamente **dimensionamento de variáveis numéricas**;\n",
    "* usando um scikit-learn **pipeline** para encadear o pré-processamento e o modelo\n",
    "  Treinamento;\n",
    "* avaliando o desempenho estatístico do nosso modelo por meio de **cross-validation**\n",
    "  em vez de uma única divisão de teste de trem.\n",
    "\n",
    "## Preparação de dados\n",
    "\n",
    "Primeiro, vamos carregar o conjunto de dados completo do censo adulto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education:</th>\n",
       "      <th>marital-status:</th>\n",
       "      <th>occupation:</th>\n",
       "      <th>relationship:</th>\n",
       "      <th>race:</th>\n",
       "      <th>sex:</th>\n",
       "      <th>capital-gain:</th>\n",
       "      <th>capital-loss:</th>\n",
       "      <th>hours-per-week:</th>\n",
       "      <th>native-country:</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass education:     marital-status:        occupation:  \\\n",
       "0   39         State-gov  Bachelors       Never-married       Adm-clerical   \n",
       "1   50  Self-emp-not-inc  Bachelors  Married-civ-spouse    Exec-managerial   \n",
       "2   38           Private    HS-grad            Divorced  Handlers-cleaners   \n",
       "3   53           Private       11th  Married-civ-spouse  Handlers-cleaners   \n",
       "4   28           Private  Bachelors  Married-civ-spouse     Prof-specialty   \n",
       "\n",
       "   relationship:  race:    sex:  capital-gain:  capital-loss:  \\\n",
       "0  Not-in-family  White    Male           2174              0   \n",
       "1        Husband  White    Male              0              0   \n",
       "2  Not-in-family  White    Male              0              0   \n",
       "3        Husband  Black    Male              0              0   \n",
       "4           Wife  Black  Female              0              0   \n",
       "\n",
       "   hours-per-week: native-country:  class  \n",
       "0               40   United-States  <=50K  \n",
       "1               13   United-States  <=50K  \n",
       "2               40   United-States  <=50K  \n",
       "3               40   United-States  <=50K  \n",
       "4               40            Cuba  <=50K  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "adult_census = pd.read_csv(\"adult-census.csv\")\n",
    "# drop the duplicated column `\"education-num\"` as stated in the first notebook\n",
    "adult_census = adult_census.drop(columns=['ID','fnlwgt:','education-num:'])\n",
    "adult_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display nice model diagram\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora retirar o alvo dos dados que usaremos para treinar nosso\n",
    "modelo preditivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"class\"\n",
    "target = adult_census[target_name]\n",
    "data = adult_census.drop(columns=target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, selecionamos apenas as colunas numéricas, como visto na anterior\n",
    "caderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    \"age\", \"capital-gain:\", \"capital-loss:\", \"hours-per-week:\"]\n",
    "\n",
    "data_numeric = data[numerical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos dividir nosso conjunto de dados em conjuntos de treinamento e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data_numeric, target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste do modelo com pré-processamento\n",
    "\n",
    "Uma variedade de algoritmos de pré-processamento no scikit-learn nos permite transformar\n",
    "os dados de entrada antes de treinar um modelo. No nosso caso, vamos padronizar o\n",
    "dados e, em seguida, treinar um novo modelo de regressão logística nessa nova versão do\n",
    "o conjunto de dados.\n",
    "\n",
    "Vamos começar imprimindo algumas estatísticas sobre os dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain:</th>\n",
       "      <th>capital-loss:</th>\n",
       "      <th>hours-per-week:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24420.000000</td>\n",
       "      <td>24420.000000</td>\n",
       "      <td>24420.000000</td>\n",
       "      <td>24420.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.598116</td>\n",
       "      <td>1045.622523</td>\n",
       "      <td>88.957207</td>\n",
       "      <td>40.386568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.638458</td>\n",
       "      <td>7162.241991</td>\n",
       "      <td>405.633599</td>\n",
       "      <td>12.299621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  capital-gain:  capital-loss:  hours-per-week:\n",
       "count  24420.000000   24420.000000   24420.000000     24420.000000\n",
       "mean      38.598116    1045.622523      88.957207        40.386568\n",
       "std       13.638458    7162.241991     405.633599        12.299621\n",
       "min       17.000000       0.000000       0.000000         1.000000\n",
       "25%       28.000000       0.000000       0.000000        40.000000\n",
       "50%       37.000000       0.000000       0.000000        40.000000\n",
       "75%       48.000000       0.000000       0.000000        45.000000\n",
       "max       90.000000   99999.000000    4356.000000        99.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que os recursos do conjunto de dados abrangem diferentes intervalos. Algum\n",
    "algoritmos fazem algumas suposições sobre as distribuições de recursos e\n",
    "normalmente normalizar recursos será útil para lidar com essas suposições.\n",
    "\n",
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p>Aqui estão alguns motivos para escalonar recursos:</p>\n",
    "<ul class=\"last simple\">\n",
    "<li>Modelos que dependem da distância entre um par de amostras, por exemplo\n",
    "vizinhos k-mais próximos, devem ser treinados em recursos normalizados para fazer cada\n",
    "recurso contribui de forma aproximadamente igual para os cálculos de distância. </li>\n",
    "<li> Muitos modelos, como regressão logística, usam um solucionador numérico (com base em\n",
    "gradiente descendente) para encontrar seus parâmetros ideais. Este solucionador converge\n",
    "mais rápido quando os recursos são dimensionados.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "Se um modelo de aprendizado de máquina requer ou não o dimensionamento dos recursos depende\n",
    "na família modelo. Modelos lineares, como regressão logística em geral\n",
    "se beneficiam do dimensionamento dos recursos, enquanto outros modelos, como árvores de decisão\n",
    "não precisa desse pré-processamento (mas não sofrerá com isso).\n",
    "\n",
    "Mostramos como aplicar essa normalização usando um transformador scikit-learn\n",
    "chamado `StandardScaler`. Este transformador muda e dimensiona cada recurso\n",
    "individualmente para que todos tenham uma média 0 e um desvio padrão da unidade.\n",
    "\n",
    "Investigaremos as diferentes etapas usadas no scikit-learn para alcançar tal\n",
    "transformação dos dados.\n",
    "\n",
    "Primeiro, é preciso chamar o método `fit`, a fim de aprender o escalonamento de\n",
    "os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6111ed7b-2d59-4946-bed8-d1090098d537\" type=\"checkbox\" checked><label class=\"sk-toggleable__label\" for=\"6111ed7b-2d59-4946-bed8-d1090098d537\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `fit` para transformadores é semelhante ao método` fit` para\n",
    "preditores. A principal diferença é que o primeiro tem um único argumento (o\n",
    "matriz de dados), enquanto o último tem dois argumentos (a matriz de dados e o\n",
    "alvo).\n",
    "\n",
    "![Predictor fit diagram](imagens/transformer.fit_.png)\n",
    "\n",
    "Neste caso, o algoritmo precisa calcular a média e o desvio padrão\n",
    "para cada recurso e armazene-os em alguns arrays NumPy. Aqui, estes\n",
    "as estatísticas são os estados do modelo.\n",
    "\n",
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">O fato de que os estados do modelo deste scaler são matrizes de meios e\n",
    "desvios padrão são específicos para o <tt class=\"docutils literal\">StandardScaler</tt>. Outro\n",
    "Os transformadores scikit-learn irão calcular diferentes estatísticas e armazená-las\n",
    "como o modelo afirma, da mesma maneira.</p>\n",
    "</div>\n",
    "\n",
    "Podemos inspecionar as médias calculadas e os desvios-padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  38.5981163 , 1045.62252252,   88.95720721,   40.38656839])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  13.63817856, 7162.09534233,  405.62529379,   12.29936908])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">scikit-learn convenção: se um atributo é aprendido a partir dos dados, seu nome\n",
    "termina com um sublinhado (i.e. <tt class=\"docutils literal\">_</tt>), as in <tt class=\"docutils literal\">mean_</tt> and <tt class=\"docutils literal\">scale_</tt> for the\n",
    "<tt class=\"docutils literal\">StandardScaler</tt>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dimensionamento dos dados é aplicado a cada recurso individualmente (ou seja, cada coluna em\n",
    "a matriz de dados). Para cada recurso, subtraímos sua média e dividimos por seu\n",
    "desvio padrão.\n",
    "\n",
    "Depois de chamar o método `fit`, podemos realizar a transformação de dados por\n",
    "chamando o método `transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76270329, -0.14599394, -0.21930883, -0.03142994],\n",
       "       [-0.85041534, -0.14599394, -0.21930883,  0.37509498],\n",
       "       [ 0.39608542, -0.14599394, -0.21930883,  1.59466973],\n",
       "       ...,\n",
       "       [-1.51032751, -0.14599394, -0.21930883, -1.65752961],\n",
       "       [ 0.83602687, -0.14599394, -0.21930883,  3.54598934],\n",
       "       [-0.33715032, -0.14599394, -0.21930883,  1.59466973]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_scaled = scaler.transform(data_train)\n",
    "data_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ilustrar o mecanismo interno do método `transform` e colocá-lo\n",
    "para perspectiva com o que já vimos com preditores.\n",
    "\n",
    "![Predictor fit diagram](imagens/transformer.transform_.png)\n",
    "\n",
    "O método `transform` para transformadores é semelhante ao método` predict`\n",
    "para preditores. Ele usa uma função predefinida, chamada de **transformation\n",
    "function** e usa os estados do modelo e os dados de entrada. No entanto, em vez de\n",
    "produzindo previsões, o trabalho do método `transform` é produzir um\n",
    "versão transformada dos dados de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, o método `fit_transform` é um método abreviado para chamar\n",
    "sucessivamente `fit` e, em seguida,` transform`.\n",
    "\n",
    "![Predictor fit diagram](imagens/transformer.fit_transform.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76270329, -0.14599394, -0.21930883, -0.03142994],\n",
       "       [-0.85041534, -0.14599394, -0.21930883,  0.37509498],\n",
       "       [ 0.39608542, -0.14599394, -0.21930883,  1.59466973],\n",
       "       ...,\n",
       "       [-1.51032751, -0.14599394, -0.21930883, -1.65752961],\n",
       "       [ 0.83602687, -0.14599394, -0.21930883,  3.54598934],\n",
       "       [-0.33715032, -0.14599394, -0.21930883,  1.59466973]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_scaled = scaler.fit_transform(data_train)\n",
    "data_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain:</th>\n",
       "      <th>capital-loss:</th>\n",
       "      <th>hours-per-week:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.442000e+04</td>\n",
       "      <td>2.442000e+04</td>\n",
       "      <td>2.442000e+04</td>\n",
       "      <td>2.442000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.070029e-16</td>\n",
       "      <td>8.018906e-16</td>\n",
       "      <td>1.849333e-15</td>\n",
       "      <td>1.202251e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.583651e+00</td>\n",
       "      <td>-1.459939e-01</td>\n",
       "      <td>-2.193088e-01</td>\n",
       "      <td>-3.202324e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.770918e-01</td>\n",
       "      <td>-1.459939e-01</td>\n",
       "      <td>-2.193088e-01</td>\n",
       "      <td>-3.142994e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.171796e-01</td>\n",
       "      <td>-1.459939e-01</td>\n",
       "      <td>-2.193088e-01</td>\n",
       "      <td>-3.142994e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.893797e-01</td>\n",
       "      <td>-1.459939e-01</td>\n",
       "      <td>-2.193088e-01</td>\n",
       "      <td>3.750950e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.768970e+00</td>\n",
       "      <td>1.381626e+01</td>\n",
       "      <td>1.051967e+01</td>\n",
       "      <td>4.765564e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  capital-gain:  capital-loss:  hours-per-week:\n",
       "count  2.442000e+04   2.442000e+04   2.442000e+04     2.442000e+04\n",
       "mean   2.070029e-16   8.018906e-16   1.849333e-15     1.202251e-15\n",
       "std    1.000020e+00   1.000020e+00   1.000020e+00     1.000020e+00\n",
       "min   -1.583651e+00  -1.459939e-01  -2.193088e-01    -3.202324e+00\n",
       "25%   -7.770918e-01  -1.459939e-01  -2.193088e-01    -3.142994e-02\n",
       "50%   -1.171796e-01  -1.459939e-01  -2.193088e-01    -3.142994e-02\n",
       "75%    6.893797e-01  -1.459939e-01  -2.193088e-01     3.750950e-01\n",
       "max    3.768970e+00   1.381626e+01   1.051967e+01     4.765564e+00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_scaled = pd.DataFrame(data_train_scaled,\n",
    "                                 columns=data_train.columns)\n",
    "data_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos facilmente combinar essas operações sequenciais com um scikit-learn\n",
    "`Pipeline`, que encadeia operações e é usado como qualquer outro\n",
    "classificador ou regressor. A função auxiliar `make_pipeline` irá criar um\n",
    "`Pipeline`: toma como argumentos as transformações sucessivas a serem realizadas,\n",
    "seguido pelo classificador ou modelo regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b81c9aef-fa6e-4e58-803b-03398946fa07\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b81c9aef-fa6e-4e58-803b-03398946fa07\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"12c01e7c-01f7-46fc-b984-447a57c44be8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"12c01e7c-01f7-46fc-b984-447a57c44be8\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5be45d33-4cdc-45e5-9a79-bc012bfbf84a\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5be45d33-4cdc-45e5-9a79-bc012bfbf84a\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `make_pipeline` não nos obrigou a dar um nome para cada etapa.\n",
    "Na verdade, foi atribuído automaticamente com base no nome das classes\n",
    "forneceu; um `StandardScaler` será um passo denominado` \"standardscaler\" `no\n",
    "pipeline resultante. Podemos verificar o nome de cada etapa do nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standardscaler': StandardScaler(),\n",
       " 'logisticregression': LogisticRegression()}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este pipeline preditivo expõe os mesmos métodos do preditor final:\n",
    "`fit` e` Predict` (e adicionalmente `Predict_proba`,` Decision_function`,\n",
    "ou `score`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(data_train, target_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos representar o mecanismo interno de um pipeline ao chamar `fit`\n",
    "pelo seguinte diagrama:\n",
    "\n",
    "![Predictor fit diagram](imagens/pipeline.fit.png)\n",
    "\n",
    "Ao chamar `model.fit`, o método` fit_transform` de cada subjacente\n",
    "transformador (aqui um único transformador) no pipeline será chamado para:\n",
    "\n",
    "- aprender seus estados de modelo interno\n",
    "- transformar os dados de treinamento. Finalmente, os dados pré-processados são fornecidos para\n",
    "  treinar o preditor.\n",
    "\n",
    "Para prever os alvos dado um conjunto de teste, usa-se o método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '<=50K', '<=50K', '<=50K', '<=50K'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_target = model.predict(data_test)\n",
    "predicted_target[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos mostrar o mecanismo subjacente:\n",
    "\n",
    "![Predictor fit diagram](imagens/pipeline.predict_.png)\n",
    "\n",
    "O método `transform` de cada transformador (aqui um único transformador) é\n",
    "chamado para pré-processar os dados. Observe que não há necessidade de chamar o `fit`\n",
    "método para esses transformadores porque estamos usando os estados do modelo interno\n",
    "calculado ao chamar `model.fit`. Os dados pré-processados são então fornecidos para\n",
    "o preditor que produzirá o alvo previsto chamando seu método\n",
    "`predict`.\n",
    "\n",
    "Em resumo, podemos verificar a pontuação do pipeline preditivo completo\n",
    "chamando o método `model.score`. Assim, vamos verificar o computacional e\n",
    "desempenho estatístico de tal pipeline preditivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A precisão usando um Pipeline é 0.801 com um tempo adequado de 0.082 seconds no 12 iterações\n"
     ]
    }
   ],
   "source": [
    "model_name = model.__class__.__name__\n",
    "score = model.score(data_test, target_test)\n",
    "print(f\"A precisão usando um {model_name} é {score:.3f} \"\n",
    "      f\"com um tempo adequado de {elapsed_time:.3f} seconds \"\n",
    "      f\"no {model[-1].n_iter_[0]} iterações\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comparar este modelo preditivo com o modelo preditivo usado em\n",
    "o notebook anterior que não escalou recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "start = time.time()\n",
    "model.fit(data_train, target_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A precisão usando um LogisticRegression é 0.801 com um tempo adequado de 0.270 seconds no 62 iterações\n"
     ]
    }
   ],
   "source": [
    "model_name = model.__class__.__name__\n",
    "score = model.score(data_test, target_test)\n",
    "print(f\"A precisão usando um {model_name} é {score:.3f} \"\n",
    "      f\"com um tempo adequado de {elapsed_time:.3f} seconds \"\n",
    "      f\"no {model.n_iter_[0]} iterações\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que dimensionar os dados antes de treinar a regressão logística foi\n",
    "benéfico em termos de desempenho computacional. Na verdade, o número de\n",
    "as iterações diminuíram, assim como o tempo de treinamento. O estatístico\n",
    "o desempenho não mudou, uma vez que ambos os modelos convergiram.\n",
    "\n",
    "<div class=\"admonition warning alert alert-danger\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Warning</p>\n",
    "<p class=\"last\">Trabalhar com dados não escalonados forçará potencialmente o algoritmo a iterar\n",
    "mais como mostramos no exemplo acima. Há também o catastrófico\n",
    "cenário em que o número de iterações necessárias é maior que o máximo\n",
    "número de iterações permitidas pelo preditor (controlado pelo<tt class=\"docutils literal\">max_iter</tt>)parâmetro. Portanto, antes de aumentar <tt class = \"docutils literal\"> max_iter </tt>, certifique-se de que os dados\n",
    "são bem dimensionados.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do modelo usando validação cruzada\n",
    "\n",
    "No exemplo anterior, dividimos os dados originais em um conjunto de treinamento e um\n",
    "conjunto de teste. Essa estratégia tem vários problemas: em um cenário onde a quantidade\n",
    "de dados é pequeno, o subconjunto usado para treinar ou testar será pequeno. Além disso, um\n",
    "a divisão única não fornece informações sobre a confiança do\n",
    "resultados obtidos.\n",
    "\n",
    "Em vez disso, podemos usar validação cruzada. A validação cruzada consiste em repetir\n",
    "o procedimento de modo que os conjuntos de treinamento e teste sejam diferentes cada\n",
    "Tempo. As métricas de desempenho estatísticas são coletadas para cada repetição e\n",
    "em seguida, agregados. Como resultado, podemos obter uma estimativa da variabilidade do\n",
    "desempenho estatístico do modelo.\n",
    "\n",
    "Observe que existem várias estratégias de validação cruzada, cada uma delas\n",
    "define como repetir o procedimento `fit` /` score`. Nesta seção, vamos\n",
    "use a estratégia K-fold: todo o conjunto de dados é dividido em partições `K`. O\n",
    "O procedimento `fit` /` score` é repetido `K` vezes onde em cada iteração` K - 1`\n",
    "as partições são usadas para ajustar o modelo e a partição `1` é usada para pontuar. O\n",
    "a figura abaixo ilustra essa estratégia K-fold.\n",
    "\n",
    "![Predictor fit diagram](imagens/k_fold.png)\n",
    "\n",
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">Esta figura mostra o caso particular da estratégia de validação cruzada K-fold.\n",
    "Conforme mencionado anteriormente, há uma variedade de diferentes tipos de validação cruzada\n",
    "estratégias. Alguns desses aspectos serão abordados com mais detalhes no futuro\n",
    "cadernos.</p>\n",
    "</div>\n",
    "\n",
    "Para cada divisão de validação cruzada, o procedimento treina um modelo em todos os\n",
    "amostras e avaliar a pontuação do modelo nas amostras azuis.\n",
    "A validação cruzada é, portanto, computacionalmente intensiva porque requer\n",
    "treinar vários modelos em vez de um.\n",
    "\n",
    "No scikit-learn, a função `cross_validate` permite fazer validação cruzada\n",
    "e você precisa passar o modelo, os dados e o destino. Desde então\n",
    "existe várias estratégias de validação cruzada, `cross_validate` leva um\n",
    "parâmetro `cv` que define a estratégia de divisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 875 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.11964297, 0.13605833, 0.1206336 , 0.13871574, 0.140939  ]),\n",
       " 'score_time': array([0.03006649, 0.0272398 , 0.03157139, 0.02211022, 0.02812767]),\n",
       " 'test_score': array([0.80454476, 0.79560811, 0.80128993, 0.7972973 , 0.80420762])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "cv_result = cross_validate(model, data_numeric, target, cv=5)\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A saída de `cross_validate` é um dicionário Python, que por padrão\n",
    "contém três entradas: (i) o tempo para treinar o modelo nos dados de treinamento\n",
    "para cada dobra, (ii) o tempo para prever com o modelo nos dados de teste\n",
    "para cada dobra e (iii) a pontuação padrão nos dados de teste para cada dobra.\n",
    "\n",
    "Definir `cv = 5` criou 5 divisões distintas para obter 5 variações para o treinamento\n",
    "e conjuntos de teste. Cada conjunto de treinamento é usado para ajustar um modelo que é então\n",
    "pontuado no conjunto de teste correspondente. Esta estratégia é chamada K-fold\n",
    "validação cruzada onde `K` corresponde ao número de divisões.\n",
    "\n",
    "Observe que, por padrão, a função `cross_validate` descarta os 5 modelos que\n",
    "foram treinados em diferentes subconjuntos sobrepostos do conjunto de dados. O objetivo de\n",
    "validação cruzada não é treinar um modelo, mas sim estimar\n",
    "aproximadamente o desempenho de generalização de um modelo que teria sido\n",
    "treinados para o conjunto de treinamento completo, juntamente com uma estimativa da variabilidade\n",
    "(incerteza sobre a precisão da generalização).\n",
    "\n",
    "Você pode passar parâmetros adicionais para `cross_validate` para obter mais\n",
    "informações, por exemplo, pontuações de treinamento. Esses recursos serão abordados em\n",
    "um futuro caderno.\n",
    "\n",
    "Vamos extrair as pontuações do teste do dicionário `cv_result` e calcular\n",
    "a precisão média e a variação da precisão nas dobras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy is: 0.801 +/- 0.004\n"
     ]
    }
   ],
   "source": [
    "scores = cv_result[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que, ao calcular o desvio padrão das pontuações de validação cruzada,\n",
    "podemos estimar a incerteza do desempenho estatístico do nosso modelo. Isso é\n",
    "a principal vantagem da validação cruzada e pode ser crucial na prática, para\n",
    "exemplo ao comparar diferentes modelos para descobrir se um é melhor\n",
    "do que o outro ou se as diferenças de desempenho estatístico estão dentro\n",
    "A incerteza.\n",
    "\n",
    "Neste caso particular, apenas as 2 primeiras casas decimais parecem ser confiáveis. Se\n",
    "você sobe neste notebook, você pode verificar se o desempenho que obtemos\n",
    "com validação cruzada é compatível com o de um único teste de trem\n",
    "dividir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caderno temos:\n",
    "\n",
    "* viu a importância de **scaling numerical variables**;\n",
    "* usou um **pipeline** para escalonamento da cadeia e treinamento de regressão logística;\n",
    "* avaliou o desempenho estatístico do nosso modelo por meio de **cross-validation**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
